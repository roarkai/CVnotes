{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a4ff96",
   "metadata": {},
   "source": [
    "# 非凸优化：SGD的opt method\n",
    "\n",
    "关注：当使用了SGD后，BGD中使用的优化工具效果变化，以及需要哪些新的工具来处理SGD中增加的随机性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a32fbf",
   "metadata": {},
   "source": [
    "## I. SGD相对BGD的优点和问题\n",
    "\n",
    "### I.1 SGD最重要的优点：运算效率\n",
    "1. 定性举例：sample中有大量相似样本时，具有明显的效率优势 \\\n",
    "· 极端假设1：sample中所有的样本是同一个样本的重复，那么GD一次迭代用掉的时间是SGD的N倍，但是效果一样 \\\n",
    "· 放松假设2：所有sample set中样本都是取值很接近的样本，SGD的优势也同样明显 \\\n",
    "· 正常假设3：一般的sample set中都有不少样本互相很接近，即使总体上很分散，SGD的效率优势也不会完全消失\n",
    "2. 参考strong convex条件下的收敛分析，虽然看起来SGD是$O(\\frac{1}{ε})$，不如Batch GD的$O(log(\\frac{1}{ε}))$，但BGD迭代1次的计算量大约是SGD迭代N次的计算量，N是样本数量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cacf96",
   "metadata": {},
   "source": [
    "### I.2 SGD带来的问题\n",
    "1. 从SGD本身抽样的方式来看，如果每次抽样不能足够random的话，得到的梯度偏差大，单词迭代优化结果不能代表整体样本，所以要shuffle every epoch\n",
    "2. 即使用了random抽样，但单次迭代得到的gradient仍然不是正确的gradient，w的迭代取值会产生严重的fluctuate。这一点可以通过数学上的方差分析看出来：\n",
    "$$\n",
    "\\begin{align}\n",
    "Var_{SGD} & = Var(div(f_{i}, d_{i}))  = Var(div(f, d))\\\\\n",
    "Var_{BGD} & =Var(\\frac{1}{N}\\underset{i}{Σ}div(f_{i}, d_{i}))=\\frac{1}{N}Var(div(f, d))\n",
    "\\end{align}\n",
    "$$\n",
    "<font color=blue>variance严重体现在w的收敛路径上是fluctuate，体现在loss curve上就是loss value的variance大。</font>如下图，用validation set画出来的test error curve图中，SGD的test error下降路径的波动要大很多。\n",
    "<img src=\"pics/sgderror.png\" alt=\"alt text\" width=\"360\">\\\n",
    "**这导致了两个问题：**\\\n",
    "(1) 即使走到local min附近，由于chase the latest data，会一直在附近fluctuate，始终无法收敛。所以SGD必须配合使用learning rate decay来实现converge。\\\n",
    "(2) SGD虽然一开始test error curve下降快，但因为一直在fluctuate，最后又是被learning rate降低强制停下来，而不是去到了真正的local min，所以收敛的结果也通常很差。\\\n",
    "(3) fluctuate的不确定性是variance的一个反映，他们还会让多次迭代得到的结果variance很大。\\\n",
    "<font color=deeppink>**所以，总的来看，SGD前期loss value下降是优点，但是其stochastic性质导致它跑多次模型得到的结果variance大，并且整体的收敛结果都不好。**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23fb6cd",
   "metadata": {},
   "source": [
    "<font color=green>**注意区分SGD中的variance和batchnorm处理的variance**：</font>\\\n",
    "batchnorm主要配合mini-batch使用。mini-batch SGD带来的variance和batchnorm要解决的covariate shift中的variance是不同来源。后者关注每个layer的input分布；前者可以视为处理的时在相同分布的input中抽样导致的随机性。batchnorm在mini-batch SGD和BGD中发挥同样的作用。但是不能用于单样本的SGD。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e42428",
   "metadata": {},
   "source": [
    "### I.3 SGD优化的主要思路\n",
    "1. 增加单次抽样数量，减少stochastic，用**mini-batch GD**。\\\n",
    "由于倒数函数特性，在N较小的时候$V_{SGD}与V_{BGD}$的差异缩小的较快，随着N的增大，不同batch大小的variance差异会减少。因此，mini-batch是很好的解决方式。\n",
    "<img src=\"pics/minibatch.png\" alt=\"alt text\" width=\"360\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03edd8",
   "metadata": {},
   "source": [
    "2. <font color=norange>**改善单次迭代的效果，既利用SGD的效率优势，又尽可能帮它在每次迭代中找到更好的方向和step size。**</font> \\\n",
    "momentum和adagrad，以及后来的RMSprop，Adam等都是从这个思路出发得到的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb6e9ae",
   "metadata": {},
   "source": [
    "## II. 针对SGD单次迭代的optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7a2d8",
   "metadata": {},
   "source": [
    "### II. 1 SGD单次迭代的控制因素\n",
    "#### II. 1.1 两个关键控制变量：learning rate和梯度，他们共同决定该次迭代的方向和步幅。\n",
    "1. **learning rate：**控制step size：η没有方向，只有大小\n",
    "2. **梯度：**同时控制方向和大小，但它提供的方向信息更重要。理解$\\nabla_{w_{l, i}}Loss$方向信息：\\\n",
    "(1) 假设$w_{l, i}$的维度是d，那么$\\nabla_{w_{l, i}}Loss$的维度也是d \\\n",
    "(2) d个元素中每个都有+/-号信息，表示梯度在对应维度上的方向，所以单个维度的方向只有正负两种 \\\n",
    "(3) d个元素的方向和大小一起决定梯度在整个空间中的方向。以d=2为例，$\\nabla_{w_{l, i}}Loss$在平面上的方向由它在两个维度上各自的方向和大小决定：\\\n",
    "[这时候，两个维度汇总后的梯度方向也是等高线的法线方向]\n",
    "<img src=\"pics/gdopt.png\" alt=\"alt text\" width=\"300\"/> \\\n",
    "(4) 注意区分函数在x点处的**梯度方向**和函数在x点处的**切线/面方向** \\\n",
    "a. 一维函数：梯度方向是$f^{'}(x)$的符号+或-，切线方向是$tagθ=f^{'}(x)$的θ \\\n",
    "b. 二维函数：梯度方向是等高线法线方向，切面方向和它不同 \\\n",
    "**所有的优化算法都是在这两个控制变量上做设计，期望达到更好的收敛效果。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d5aba",
   "metadata": {},
   "source": [
    "#### II. 1.2 SGD优化方法的设计思路\n",
    "<font color=norange>**出发点：尽可能让单次迭代达到BGD的最优迭代状态**</font>\n",
    "1. BGD的最优迭代方式\n",
    "$$\n",
    "\\begin{align}\n",
    "w^{[t+1]} & = w^{[t]} -\\eta*\\nabla _{w} f(w^{[t]}) \\\\\n",
    "\\eta_i & =\\frac{1}{\\lambda_i}，\\lambda是Hessian的特征值\\\\\n",
    "最终迭代式： \\\\\n",
    "w_i^{[t+1]} & = w_i^{[t]} -\\frac{1}{\\lambda_i}*\\nabla _{w_i} f(w^{[t]}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "2. SGD近似BGD迭代的思路 \\\n",
    "(1) BGD用了所有样本来计算梯度，而SGD只用了mini-batch，那么一种自然的思路是，记录历史gradient，用来计算历史加权平均作为BGD梯度的近似。\\\n",
    "(2) BGD中配合梯度的最优learning rate是Hessian matrix的特征值倒数$\\frac{1}{\\lambda}$。计算特征值复杂度太大，但同样的思路是找一个近似值，然后在SGD中用该值的历史加权来近似它。\n",
    "3. <font color=norange>momentum和adagrad，以及后来的RMSprop，Adam等算法共同的一个关键特点就是用了**exponentially weighted moving average:**</font> \\\n",
    "(1) 以Momentum为例，running average of single sample gradient是overall gradient of the entire training set的近似。\\\n",
    "(2) 在RMSprop中，running average of squared gradient则是对2nd raw moment(the uncentered variance) of the gradient的估计。\\\n",
    "**<font color=green>这些算法作者原本的设计出发点不一定是这个逻辑，但结果本身体现了上述思想。</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018882ba",
   "metadata": {},
   "source": [
    "### II. 2 Momentum\n",
    "#### II.2.1 思路\n",
    "1. 要解决的问题：减少收敛路径在某些维度上的**oscillate**，增加learning rate，加速收敛\n",
    "2. 分析思路：\\\n",
    "(1) oscillate产生的原因，单个维度上的梯度方向+/-交叠 \\\n",
    "(2) 可以减轻这一现象的方式：取历史平均可以消减这种+/-交叠\n",
    "3. 解决办法：用gradient的历史加权平均来代替梯度，主要是控制方向，也含有step size信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247ca94",
   "metadata": {},
   "source": [
    "#### II.2.2 算法迭代式\n",
    "1. 迭代方式\n",
    "第一种迭代式\n",
    "$$\n",
    "\\begin{align}\n",
    "v_0 & = 0 \\\\\n",
    "v_{t+1} & = \\rho v_t+\\nabla f(w_t) \\ \\#当前步是梯度的历史加权\\\\\n",
    "w_{t+1} & = w_t-\\alpha v_{t+1}\n",
    "\\end{align}\n",
    "$$\n",
    "第二种等价迭代式：\n",
    "$$\n",
    "\\begin{align}\n",
    "v_{t+1} & = \\beta v_t+(1-\\beta )\\nabla f(w_t) ...[1]  \\\\\n",
    "w_{t+1} & = w_t-\\gamma v_{t+1} ...[2]\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "<font color=green>β默认取0.9，*原因见”why moments really works”。*在凸条件下，condition number越大，β的最优取值越大。</font>\\\n",
    "第三种等价迭代式：\n",
    "$$\n",
    "\\begin{align}\n",
    "v_{t+1} & = \\rho v_t-\\alpha \\nabla f(w_t)   \\\\\n",
    "w_{t+1} & = w_t+v_{t+1} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ed294",
   "metadata": {},
   "source": [
    "2. (续)算法等价性说明 \\\n",
    "<font color=gray>(1) 第一种和第二种迭代式等价：\\\n",
    "取$\\rho=\\frac{\\beta}{1-\\beta}$,有$\\frac{1}{1-\\beta}=1+\\rho$。代入[1]式有:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{(1-\\beta )} v_{t+1} & = \\frac{\\beta }{(1-\\beta )}v_t+\\nabla f(w_t) \\\\\n",
    "(1+\\rho) v_{t+1} & = \\rho v_t + \\nabla f(w_t)...[3] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "$取\\gamma=\\alpha(1+\\rho)$，代入[2]式有：\n",
    "$$\n",
    "w_{t+1} = w_t-\\alpha(1+\\rho)v_{t+1}...[4]\n",
    "$$\n",
    "可见，[3]和[4]与第一种迭代式相同。</font> \\\n",
    "<font color=gray>(2) 第一种和第三种迭代式等价：直接将v代入w的迭代式展开即可。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910090e9",
   "metadata": {},
   "source": [
    "#### II.2.3 理解历史加权：exponentially weighted moving average\n",
    "1. 递推式\n",
    "$$\n",
    "\\begin{align}\n",
    "v_{0} & =0 \\\\\n",
    "v_{1} & =β*v_{0}+(1-β)*θ_{1} \\\\\n",
    "v_{2} & =β*v_{1}+(1-β)*θ_{2}=β^{2}*v_{0}+β*(1-β)*θ_{1}+(1-β)*θ_{2} \\\\\n",
    "v_{3} & =β*v_{2}+(1-β)*θ_{3} \\\\\n",
    "& = β^{3}*v_{0}+β^{2}*(1-β)*θ_{1}+β*(1-β)*θ_{2}+(1-β)*θ_{3}\\\\\n",
    " …     \\\\ \n",
    "v_{t} & =β*v_{t-1}+(1-β)*θ_{t} \\\\\n",
    "& =(1-β)*(β^{t-1}*θ_{1}+β^{t-2}*θ_{2}+...+β^{1}*θ_{t-1}+β^{0}*θ_{t}) \\\\\n",
    "& =(1-β)*[(β^{t-1}, β^{t-2}, ..., β^{0})\\otimes(θ_{1}, θ_{2}, ..., θ_{t})]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b429192",
   "metadata": {},
   "source": [
    "2. 偏差修正 \\\n",
    "·前面迭代式存在的问题：由于$v_{0}=0$，导致初始状态的加权平均结果严重偏小 \\\n",
    "**修正方式：**\n",
    "$$\n",
    "\\begin{align}\n",
    "v^{'}_{t}&  =\\frac{v_{t}}{1-β^{t}} \\\\\n",
    "1-β^{t}& =(1-β)*(β^{t-1}, β^{t-2}, ..., β^{0}) \\\\\n",
    "\\frac{v_{t}}{1-β^{t}}& =\\frac{β^{t-1}*θ_{1}+β^{t-2}*θ_{2}+...+β^{1}*θ_{t-1}+β^{0}*θ_{t}}{β^{t-1}+ β^{t-2}+ ...+ β^{0}}\n",
    "\\end{align}\n",
    "$$\n",
    "<font color=blue>修正后得到的LHS是$θ_{1}, ..., θ_{t}$的加权平均</font> \\\n",
    "<font color=orange>实践中，由于迭代时间通常很长，$v_0$的取值对最终结果影响不大，所以一般不做偏差修正，这里只是说明理论情况。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f41283",
   "metadata": {},
   "source": [
    "3. 递推式特点：\\\n",
    "一种粗略的计算方式是，$v_{t}$主要用的是过去$\\frac{1}{1-β}$个时间段的数据。\\\n",
    "比如$\\beta=0.9$，那么$v$主要用历史上10个时点的数据的加权平均。分析：\\\n",
    "$$\n",
    "\\begin{align}\n",
    "\\because \\lim_{x \\to \\infty} (1-x)^{\\frac{1}{x} }&=\\frac{1}{e}\\approx 0.37 \\\\\n",
    "\\therefore \\lim_{\\beta \\to 1} \\beta^{\\frac{1}{1-\\beta}}&\\approx 0.37 \\\\\n",
    "\\beta = 0.9时，\\beta^{\\frac{1}{1-\\beta}}&=0.9^{10}=0.348，从占比看，10个时点外的值影响小\\\\\n",
    "\\beta = 0.98时，\\beta^{\\frac{1}{1-\\beta}}&=0.98^{50}=0.364，从占比看，50个时点外的值影响小\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75c7ca",
   "metadata": {},
   "source": [
    "#### II.2.4 momentum的优化过程\n",
    "<font color=green>[参考：why momentum really works]</font>\n",
    "1. 迭代过程中，那些$\\lambda_i$值较大的方向会先收敛，他们的收敛导致loss在初始阶段也能快速下降。\n",
    "2. 那些较小的$\\lambda_j$值对应的方向收敛慢。论文中用多项式线性模型为例(但没有提供一般化的证明)说明了：$\\lambda$最小的方向是最容易受样本变化而导致w收敛结果大幅变化的方向。所以，在最后那些$\\lambda$最小的方向收敛之前停止迭代可以带来更好的generalizing results。**这给early stopping提供了依据。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a421197",
   "metadata": {},
   "source": [
    "#### II.2.5 尚未解决的优化问题\n",
    "原本单一learning rate只能迁就Hessian对应的$\\frac{1}{maxλ_{i}}$，导致迭代速度慢。用了momentum之后，虽然可以放大learning rate，但是每个维度仍然使用相同的learning rate。 \\\n",
    "<font color=red>如果能有一种改进，能让learning rate近似hessian的特征值，那么与momentum配合就能起到近似BGD的效果。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ade09",
   "metadata": {},
   "source": [
    "### II. 3 AdaGrad\n",
    "#### II.3.1 背景：解决sparse feature收敛慢的问题\n",
    "<font color=norange>论文中提出的具体问题是结合应用场景的：加速sparse feature对应的weight的迭代速度。</font>\n",
    "1. feature有dense feature和sparse feature两种，前一种经常出现，后一种则出现频次低。一个sample对应的input中，没有出现的feature取值为0。以nlp的bag of words模型为例，如果每个句子是一个input vector，上面很多element取值对应的是罕见词，大多数时候都是0，而与常用词对应的feature则经常取1。\n",
    "2. 用SGD训练时，取0的feature无法让对应的weight进行迭代，只有取1的feature才能让对应的weight正常迭代。这就带来问题：常见词对应的weight迭代较快，sparse feature对应的weight则迭代很慢。即使用了momentum，sparse features也会因为平均gradient很小而迭代的很慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b597a8e",
   "metadata": {},
   "source": [
    "#### II.3.2 思路\n",
    "1. 用adaptive learning rate加速收敛速度。放大sparse feature的learning rate，缩小dense feature的learning rate。\n",
    "2. dense feature的梯度很少为0，所以历史梯度$|g_{den,t}|>0$,sparse feature则经常出现$|g_{sp,t}|=0$。用root of sum of squared gradient可以反映出这种差异。因此，可以让每个维度的learning rate与该维度上的sum of squared gradient成反比。\\\n",
    "<font color=deeppink>**[rk's note]为什么不用sum of absolute gradient，而要用root of sum of squared gradient：**后者更smooth，有更好的优化性质</font>\n",
    "3. 预期的效果是当某个维度上的$|g_{i,t}|$均值较大值时(A图)，降低step size；反之，当$|g_{i,t}|$的均值较小时(B图)，提高step size。\n",
    "<img src=\"pics/adagrad.png\" alt=\"alt text\" width=\"360\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05505504",
   "metadata": {},
   "source": [
    "#### II.3.3 效果\n",
    "1. 如果梯度绝对值持续较大，那么learning rate会缩小梯度的step size；反之，learning rate会放大梯度的step size。\n",
    "2. 但该算法带来一个问题：AdaGrad中adaptive learning rate随时间累积，当迭代次数过高时，会导致step size→0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64046526",
   "metadata": {},
   "source": [
    "### II. 4 RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8234a24",
   "metadata": {},
   "source": [
    "#### II.4.1 背景：对BGD有效的RProp算法在SGD上不适用\n",
    "1. BGD上有一种很简单但是有效的RProp算法：\n",
    "$$w^{[t]}_{l,i}=w^{[t-1]}-η*g_{l, i}$$\n",
    "$如果连续两次gradient同号++或- -，则g_{l, i}=g_{l, i}*1.2$\n",
    "$如果连续两次gradient的符号变化+-或-+，那么g_{l, i}=g_{l, i}*0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9856c52",
   "metadata": {},
   "source": [
    "2. **RProp用在SGD上效果差，问题是**：\\\n",
    "SGD能达到BGD的效果，是因为虽然单次mini-batch抽样的梯度和BGD差异大，但是多次连续抽样的平均gradient与BGD做一次的效果接近。但是RProp用在SGD上时，会放大SGD与BGD的差异。\\\n",
    "<font color=brown>Hinton举了一个例子：所有样本分成10份，合在一起计算的梯度是0，但分成10个nimi-batch后，有9个的gradient是0.1，最后1个mini-batch的梯度是-0.9。在BGD中，Rprop会停在原地，而在SGD中，会走9步，然后退1步。这导致SGD的收敛路径和BGD中出现非常大的差异。</font>\n",
    "<img src=\"pics/hinton1.png\" alt=\"alt text\" width=\"560\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c557f6e",
   "metadata": {},
   "source": [
    "#### II.4.2 思路\n",
    "1. hinton设计RMSprop的想法是在Rprop基础上改造，以适用于SGD。方法是用adjusted exponential average of squared gradient来调节learning rate。\\\n",
    "<font color=norange>exponential average of squared gradient of the mini-batch可以视为对样本总体的squared gradient的估计。</font>\n",
    "<img src=\"pics/hinton2.png\" alt=\"alt text\" width=\"560\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ac337",
   "metadata": {},
   "source": [
    "2. 另一种理解思路是：用running average of squared gradient来代替Adagrad中的sum of squared gradient.从而解决了AdaGrad中adaptive learning rate随迭代次数增加，step size→0的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa906ed",
   "metadata": {},
   "source": [
    "3. **[rk’s note]从梯度绝对值与step size的关系理解：**\n",
    "$$\n",
    "\\begin{align}\n",
    "lr&=\\frac{η}{\\sqrt{M_{2}(w)+ε}}\\\\\n",
    "M_{2}^{[t+1]}(w)&=β*M_{2}^{[t]}(w)+(\\nabla_{w} L)^{2}\n",
    "\\end{align}\n",
    "$$\n",
    "可见，决定lr大小的是$|\\nabla_{w} L|$的历史值，而不受其方向影响。其作用方式是:\\\n",
    "(1) 如果$|\\nabla_{w} L|$的值一直很大，那么step size减少 \\\n",
    "(2) 如果一直很小，step size放大 \\\n",
    "(3) 如果在过去几步中经历了由大到小，那么step size会比之前放大一些 \\\n",
    "(4) 果在过去几步中经历了由小到大，那么step size会比之前缩小一些 \\\n",
    "这符合梯度本身大小与期望的step size的关系。梯度绝对值很大时，图形向上或者向下的趋势很陡，这时候用了梯度的方向+-信息后，会希望step size小一些。反之亦然。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d514d2",
   "metadata": {},
   "source": [
    "4. adam论文的观点：用running average of squared gradient来近似uncentered variance(2nd moment) of the gradient。\\\n",
    "*[rk’s补充]相当于假设了BGD条件下用uncentered variance of gradient的倒数来调节stepsize的合理性，然后考虑到SGD场景，就用adjusted exponential average  of squared gradient。*\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{N}Σx_{i}^2 & ＝uncentered\\ \\ variance\\\\\n",
    "\\frac{1}{N}Σ(x_{i}-\\bar x)^2 & ＝variance\n",
    "\\end{align}\n",
    "$$\n",
    "<font color=red>*注：在多元正态分布中，reverse Hessian就是covariate matrix of w。但前提是covariance matrix是用w的样本构建的。但梯度迭代过程中的中间值不是样本，不能混淆概念。*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ffeb05",
   "metadata": {},
   "source": [
    "### II. 5 Adam\n",
    "#### II.5.1 思路\n",
    "**让RMSprop调节learning rate，让momentum调节gradient。**\n",
    "1. RMSprop只调整learning rate，不会影响方向。方向由momentum计算的历史梯度的加权来决定，一方面减少了oscillate，同时又可以更好地得到真实梯度的近似，减少fluctuate。\n",
    "2. momentum中各维度learning rate相同，加速收敛依靠增加所有维度的learning rate。加上PMSprop后，实现了adaptive learning rate。如果维度上的梯度绝对值持续较大，那么久减少step size；如果维度上的梯度绝对值持续较小，久增加step size。\n",
    "#### II.5.2 优点\n",
    "几种典型问题都能处理：\n",
    "1. cross ravine：cross ravine在陡峭的方向上不能有太大的step size，如果只用momentum，还是会对learning rate有限制。RMSprop进一步减少了cross ravine方向的step size，放大了gradient较小的方向上的step size。\n",
    "2. oscillate：连续两步梯度方向不同的时候，分母变化不大，不影响momentum的机制发挥作用\n",
    "3. sparse feature加速迭代：RMSProp是对Adagrad作用机制的优化，而momentum用梯度的历史均值可能会一定程度上减弱sparse feature出现时获得的梯度信息。\n",
    "#### II.5.3 遗留问题\n",
    "<font color=red>与BGD的最优解相比，RMSprop在控制learning rate的时候用的root of running average of squared gradient不是hessian matrix的特征值的近似。尽管他们也起到了类似的调节作用，但是在于梯度信息的配合上，仍然不如$\\lambda$那么好。</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
